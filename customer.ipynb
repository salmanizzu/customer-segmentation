{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation and Recommendation System Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we aim to enhance marketing strategies and increase sales for an online retail business by analyzing transactional data from a UK-based retailer. The dataset, which spans from 2010 to 2011, contains detailed information about customer purchases, including transaction dates, product descriptions, quantities, and prices.\n",
    "\n",
    "### Project Objectives\n",
    "\n",
    "1. Customer Segmentation: To group customers into distinct segments based on their purchasing behavior using the K-means clustering algorithm. This segmentation will allow the business to tailor marketing strategies to different customer groups effectively.\n",
    "2. Recommendation System: To develop a recommendation system that suggests top-selling products to customers within each segment who have not yet purchased those items. This will help boost sales and enhance customer satisfaction by providing personalized product recommendations.\n",
    "\n",
    "## Data Overview\n",
    "\n",
    "The dataset includes key information that helps us understand customer behavior and product preferences. Some of the most relevant features are:\n",
    "\n",
    "* InvoiceNo: Unique identifier for each transaction.\n",
    "* StockCode: Unique identifier for each product.\n",
    "* Description: A brief description of the product.\n",
    "* Quantity: Number of products purchased in each transaction.\n",
    "* InvoiceDate: The date when the transaction occurred.\n",
    "* UnitPrice: Price per product unit.\n",
    "* CustomerID: Unique identifier for each customer.\n",
    "* Country: The country where the customer is based.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "To ensure the dataset is suitable for analysis, we will clean and preprocess the data by:\n",
    "\n",
    "* Handling missing or null values, especially in crucial fields like `CustomerID`.\n",
    "* Removing duplicate entries or erroneous records (e.g., transactions with negative quantities).\n",
    "* Converting the `InvoiceDate` to a more usable format, such as extracting year, month, and day features.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "To create customer-level insights, we will engineer the following features:\n",
    "\n",
    "* Recency: The time since a customer's last purchase.\n",
    "* Frequency: The total number of purchases made by the customer.\n",
    "* Monetary Value: The total amount spent by the customer.\n",
    "\n",
    "These features will allow us to perform clustering and distinguish between different customer groups.\n",
    "\n",
    "## Customer Segmentation\n",
    "\n",
    "Using the K-means clustering algorithm, we will group customers based on the engineered features. This step will help us understand customer behavior patterns, such as:\n",
    "\n",
    "* High-frequency buyers vs. occasional buyers.\n",
    "* High spenders vs. low spenders.\n",
    "* Recency of the last purchase.\n",
    "* By identifying these distinct segments, the business can adjust its marketing strategies, such as offering promotions or discounts to * retain valuable customers or re-engaging dormant customers.\n",
    "\n",
    "## Recommendation System\n",
    "\n",
    "After segmentation, we will build a recommendation system that:\n",
    "\n",
    "* Identifies the top-selling products in each segment.\n",
    "* Recommends these products to customers who havenâ€™t yet purchased them.\n",
    "* This system will enhance the shopping experience by helping customers discover relevant products while also increasing sales for the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Understanding and Exploration\n",
    "\n",
    "In this first step of the project, we will explore the dataset to understand its structure, \n",
    "identify any data quality issues, and gain insights into the key features that will be used \n",
    "for customer segmentation and recommendations. This exploratory analysis will provide us \n",
    "with an initial understanding of the data, helping to inform subsequent steps such as \n",
    "feature engineering and model building.\n",
    "\n",
    "#### The main tasks in this step include:\n",
    "- **Loading the dataset** into a pandas DataFrame for analysis.\n",
    "- **Initial inspection** of the data to examine its structure, column names, and data types.\n",
    "- **Checking for missing values** and analyzing the distribution of different features.\n",
    "- **Reviewing basic statistics** such as mean, median, and distribution for numerical features.\n",
    "- **Identifying categorical features** and understanding their potential use in segmentation and recommendations.\n",
    "- **Inspecting anomalies** like negative values for quantity or price and handling them as needed.\n",
    "- **Visualizing key distributions** to better understand the data patterns and relationships.\n",
    "\n",
    "By thoroughly understanding the dataset, we will lay the foundation for effective data preprocessing, \n",
    "feature engineering, and model development in the subsequent steps of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Understanding and Exploration\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "file_path = 'data/retail-data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initial inspection of the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())  # This will show column names, data types, and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the dataset:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())  # Display the first few rows to get an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values count per column:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values count per column:\")\n",
    "print(df.isnull().sum())  # Summarize missing values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical features:\n",
      "            Quantity      UnitPrice     CustomerID\n",
      "count  541909.000000  541909.000000  406829.000000\n",
      "mean        9.552250       4.611114   15287.690570\n",
      "std       218.081158      96.759853    1713.600303\n",
      "min    -80995.000000  -11062.060000   12346.000000\n",
      "25%         1.000000       1.250000   13953.000000\n",
      "50%         3.000000       2.080000   15152.000000\n",
      "75%        10.000000       4.130000   16791.000000\n",
      "max     80995.000000   38970.000000   18287.000000\n"
     ]
    }
   ],
   "source": [
    "# Generate basic statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical features:\")\n",
    "print(df.describe())  # Shows mean, median, standard deviation, and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in categorical columns:\n",
      "InvoiceNo: 25900 unique values\n",
      "StockCode: 4070 unique values\n",
      "Description: 4223 unique values\n",
      "InvoiceDate: 23260 unique values\n",
      "Country: 38 unique values\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of categorical features (if applicable)\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for negative quantities or unit prices:\n",
      "Number of rows with negative values: 10626\n"
     ]
    }
   ],
   "source": [
    "# Checking for anomalies (e.g., negative quantities or unit prices)\n",
    "print(\"\\nChecking for negative quantities or unit prices:\")\n",
    "negative_values = df[(df['Quantity'] < 0) | (df['UnitPrice'] < 0)]\n",
    "print(f\"Number of rows with negative values: {negative_values.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing\n",
    "\n",
    "In this step, we will clean and preprocess the data to ensure it is ready for feature engineering and modeling. \n",
    "The following actions will be taken:\n",
    "- **Handling Missing Values**: We will drop rows where `CustomerID` is missing, as these transactions cannot be associated with a customer for segmentation. We will also remove rows with missing values in the `Description` column, as it is not essential for segmentation.\n",
    "- **Removing Negative Values**: We will remove rows where `Quantity` or `UnitPrice` is negative, assuming these represent returns or data entry errors that are not useful for the scope of this project.\n",
    "- **Dropping the Description Column**: Since the `Description` column is not relevant for our analysis, we will drop it from the dataset.\n",
    "- **Converting Date Columns**: We will convert the `InvoiceDate` column to a datetime format to facilitate time-based analysis (e.g., calculating recency).\n",
    "- **Handling Outliers**: If any extreme outliers significantly skew the analysis, we will consider removing or capping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# 1. Drop rows with missing CustomerID as these cannot be used for customer segmentation\n",
    "df_cleaned = df.dropna(subset=['CustomerID'])\n",
    "\n",
    "# 2. Drop rows with missing Description (not needed for our analysis)\n",
    "df_cleaned = df_cleaned.dropna(subset=['Description'])\n",
    "\n",
    "# 3. Remove negative Quantity and UnitPrice values, assuming they represent returns or data errors\n",
    "df_cleaned = df_cleaned[(df_cleaned['Quantity'] > 0) & (df_cleaned['UnitPrice'] > 0)]\n",
    "\n",
    "# 4. Drop the Description column, as it's not necessary for segmentation or recommendation\n",
    "df_cleaned = df_cleaned.drop(columns=['Description'])\n",
    "\n",
    "# 5. Convert InvoiceDate to datetime format for time-based analysis\n",
    "df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])\n",
    "\n",
    "# 6. Optional: Reset the index after cleaning\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after preprocessing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397884 entries, 0 to 397883\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    397884 non-null  object        \n",
      " 1   StockCode    397884 non-null  object        \n",
      " 2   Quantity     397884 non-null  int64         \n",
      " 3   InvoiceDate  397884 non-null  datetime64[ns]\n",
      " 4   UnitPrice    397884 non-null  float64       \n",
      " 5   CustomerID   397884 non-null  float64       \n",
      " 6   Country      397884 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 21.2+ MB\n",
      "None\n",
      "\n",
      "First few rows of cleaned data:\n",
      "  InvoiceNo StockCode  Quantity         InvoiceDate  UnitPrice  CustomerID  \\\n",
      "0    536365    85123A         6 2010-12-01 08:26:00       2.55     17850.0   \n",
      "1    536365     71053         6 2010-12-01 08:26:00       3.39     17850.0   \n",
      "2    536365    84406B         8 2010-12-01 08:26:00       2.75     17850.0   \n",
      "3    536365    84029G         6 2010-12-01 08:26:00       3.39     17850.0   \n",
      "4    536365    84029E         6 2010-12-01 08:26:00       3.39     17850.0   \n",
      "\n",
      "          Country  \n",
      "0  United Kingdom  \n",
      "1  United Kingdom  \n",
      "2  United Kingdom  \n",
      "3  United Kingdom  \n",
      "4  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# Summary of the cleaned data\n",
    "print(\"Data after preprocessing:\")\n",
    "print(df_cleaned.info())\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Feature Engineering\n",
    "\n",
    "In this step, we will create customer-centric features that will be essential for segmentation using the RFM (Recency, Frequency, Monetary) model. These features will capture the purchasing behavior of each customer, summarizing their activity into three key metrics:\n",
    "\n",
    "- **Recency**: How recently a customer made their last purchase. This will be calculated by finding the difference between the last transaction date in the dataset and each customerâ€™s most recent purchase date.\n",
    "- **Frequency**: The total number of transactions made by each customer. This will be measured by counting the number of unique invoices per customer.\n",
    "- **Monetary Value**: The total amount of money spent by each customer, computed by summing the product of `Quantity` and `UnitPrice` for each customerâ€™s transactions.\n",
    "\n",
    "Once these features are created, the data will be aggregated at the customer level for segmentation. We will also inspect the distributions of these new features to understand customer behavior patterns before proceeding to clustering.\n",
    "\n",
    "Steps:\n",
    "1. Calculate **Recency**, **Frequency**, and **Monetary Value** for each customer.\n",
    "2. Aggregate the data by `CustomerID` to create a customer-level DataFrame.\n",
    "3. Analyze and inspect the distributions of these features to ensure they make sense for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering\n",
    "\n",
    "# 1. Set a reference date for calculating recency (maximum InvoiceDate in the dataset)\n",
    "latest_date = df_cleaned['InvoiceDate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a customer-level DataFrame\n",
    "rfm = df_cleaned.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (latest_date - x.max()).days,  # Recency: days since last purchase\n",
    "    'InvoiceNo': 'nunique',  # Frequency: number of unique invoices\n",
    "    'Quantity': 'sum',  # Total Quantity purchased by the customer\n",
    "    'UnitPrice': 'mean'  # Average Unit Price (optional, to explore pricing sensitivity)\n",
    "})\n",
    "\n",
    "# Rename columns for clarity\n",
    "rfm.columns = ['Recency', 'Frequency', 'TotalQuantity', 'AvgUnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate the Monetary Value by multiplying UnitPrice and Quantity in each transaction\n",
    "df_cleaned['Monetary'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']\n",
    "monetary = df_cleaned.groupby('CustomerID')['Monetary'].sum()  # Sum Monetary values for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge the monetary feature back into the RFM DataFrame\n",
    "rfm = rfm.merge(monetary, on='CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Optional: Calculate additional features like Average Order Value, Product Diversity\n",
    "rfm['AvgOrderValue'] = rfm['Monetary'] / rfm['Frequency']  # Average order value\n",
    "product_diversity = df_cleaned.groupby('CustomerID')['StockCode'].nunique()  # Number of unique products purchased\n",
    "rfm = rfm.merge(product_diversity, on='CustomerID', how='left').rename(columns={'StockCode': 'ProductDiversity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFM Customer-level DataFrame:\n",
      "            Recency  Frequency  TotalQuantity  AvgUnitPrice  Monetary  \\\n",
      "CustomerID                                                              \n",
      "12346.0         325          1          74215      1.040000  77183.60   \n",
      "12347.0           1          7           2458      2.644011   4310.00   \n",
      "12348.0          74          4           2341      5.764839   1797.24   \n",
      "12349.0          18          1            631      8.289041   1757.55   \n",
      "12350.0         309          1            197      3.841176    334.40   \n",
      "\n",
      "            AvgOrderValue  ProductDiversity  \n",
      "CustomerID                                   \n",
      "12346.0      77183.600000                 1  \n",
      "12347.0        615.714286               103  \n",
      "12348.0        449.310000                22  \n",
      "12349.0       1757.550000                73  \n",
      "12350.0        334.400000                17  \n"
     ]
    }
   ],
   "source": [
    "# Summary of the engineered features\n",
    "print(\"RFM Customer-level DataFrame:\")\n",
    "print(rfm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for RFM features:\n",
      "           Recency    Frequency  TotalQuantity  AvgUnitPrice       Monetary  \\\n",
      "count  4338.000000  4338.000000    4338.000000   4338.000000    4338.000000   \n",
      "mean     91.536422     4.272015    1191.289073      4.467773    2054.266460   \n",
      "std     100.014169     7.697998    5046.081546     34.211451    8989.230441   \n",
      "min       0.000000     1.000000       1.000000      0.122500       3.750000   \n",
      "25%      17.000000     1.000000     160.000000      2.203728     307.415000   \n",
      "50%      50.000000     2.000000     379.000000      2.917611     674.485000   \n",
      "75%     141.000000     5.000000     992.750000      3.829784    1661.740000   \n",
      "max     373.000000   209.000000  196915.000000   2033.100000  280206.020000   \n",
      "\n",
      "       AvgOrderValue  ProductDiversity  \n",
      "count    4338.000000       4338.000000  \n",
      "mean      419.166289         61.501153  \n",
      "std      1796.537944         85.366768  \n",
      "min         3.450000          1.000000  \n",
      "25%       178.625000         16.000000  \n",
      "50%       293.900000         35.000000  \n",
      "75%       430.113750         77.000000  \n",
      "max     84236.250000       1787.000000  \n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for the RFM features\n",
    "print(\"\\nSummary statistics for RFM features:\")\n",
    "print(rfm.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
